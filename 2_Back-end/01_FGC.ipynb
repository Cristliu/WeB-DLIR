{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch_Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model K1 K2 w1 w2  ROC_AUC  PRC_AUC  TimeCost\n",
      "0  random  2  1  1  3    0.986   0.9665   27.9673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "import time\n",
    "import socket\n",
    "import struct\n",
    "import copy\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "import warnings\n",
    "\n",
    "\n",
    "# #######Define logdf to store logs for visualization\n",
    "# Logdf = pd.DataFrame(columns=('Model', 'K1', 'K2', 'w1', 'w2', 'ROC_AUC', 'PRC_AUC', 'TimeCost'))\n",
    "\n",
    "# mlist=[0,1,1,1,1,1,1,2,3,4,5]\n",
    "# nlist=[1,0,1,2,3,4,5,1,1,1,1]\n",
    "# for K_1 in range(1,5):\n",
    "#     for K_2 in range(1,5):\n",
    "#         for k in range(len(mlist)):\n",
    "#             w_1 = mlist[k]\n",
    "#             w_2 = nlist[k]\n",
    "\n",
    "\n",
    "#############Loading raw data#############\n",
    "dfinit = pd.read_csv(\"data/loginmysql-db_for_exp.csv\")\n",
    "dfinit.head()\n",
    "\n",
    "#################Data feature processing#######################\n",
    "\n",
    "dfinit['tih'] = pd.to_datetime(dfinit['tih'], format='%Y-%m-%d')\n",
    "dfinit['day']=dfinit['tih'].dt.day\n",
    "dfinit['hour']=dfinit['tih'].dt.hour\n",
    "\n",
    "groups_sip_dip = dfinit.groupby(['sip','dip'])\n",
    "groups_sip_dip_sum = pd.DataFrame(dfinit.groupby(['sip','dip'])['num'].sum())\n",
    "groups_sip_dip_sqlsum = pd.DataFrame(dfinit.groupby(['sip','dip'])['sqlnum'].sum())\n",
    "groups_sip_dip_dayuniq = pd.DataFrame(dfinit.groupby(['sip','dip'])['day'].nunique())\n",
    "\n",
    "dfdict = {}\n",
    "i = 0\n",
    "for (k1,k2),groupi in groups_sip_dip:\n",
    "    dfexpi_sip_dip = groupi\n",
    "    dfexpi_sip_dip['numSum'] = groups_sip_dip_sum['num'][i]\n",
    "    dfexpi_sip_dip['sqlnumSum'] = groups_sip_dip_sqlsum['sqlnum'][i]\n",
    "    dfexpi_sip_dip['nday'] = groups_sip_dip_dayuniq['day'][i]\n",
    "    dfdict[i] = dfexpi_sip_dip\n",
    "    i+=1\n",
    "dfdict_pd = pd.concat(list(dfdict.values()), ignore_index=True)\n",
    "# dfdict_pd.head()\n",
    "\n",
    "df = copy.deepcopy(dfdict_pd)\n",
    "for i in range(df.shape[0]):\n",
    "    df.loc[i,'sip'] = socket.ntohl(struct.unpack(\"I\",socket.inet_aton(str(df.loc[i,'sip'])))[0])\n",
    "    df.loc[i,'dip'] = socket.ntohl(struct.unpack(\"I\",socket.inet_aton(str(df.loc[i,'dip'])))[0])\n",
    "\n",
    "df['No.'] = \"\"\n",
    "for i in range(df.shape[0]):\n",
    "    df.loc[i,'No.']=i\n",
    "# df.head()\n",
    "\n",
    "df_only_login_init = df[df[\"dbtype\"]==\"0\"]\n",
    "df_with_db_init = df[df[\"dbtype\"]==\"db\"]\n",
    "\n",
    "df_only_login = copy.deepcopy(df_only_login_init)\n",
    "df_with_db = copy.deepcopy(df_with_db_init)\n",
    "\n",
    "\n",
    "#############Defining Parameters and Functions#############\n",
    "\n",
    "# Calculate the distance of each data point to its cluster center\n",
    "def getDistanceByPoint(data, model,oridata, div):\n",
    "    distance = pd.Series()\n",
    "    if div == True:\n",
    "        for i in range(0,len(data)):\n",
    "            Xa = np.array(data.loc[i])\n",
    "            Xb = model.cluster_centers_[model.labels_[i]]\n",
    "            distance.at[i] = np.linalg.norm(Xa-Xb)\n",
    "            distance.at[i] = distance.at[i] / oridata.loc[i,\"nday\"] #######Divide by the frequency to get the anomaly score\n",
    "    else:\n",
    "        for i in range(0,len(data)):\n",
    "            Xa = np.array(data.loc[i])\n",
    "            Xb = model.cluster_centers_[model.labels_[i]]\n",
    "            distance.at[i] = np.linalg.norm(Xa-Xb)\n",
    "\n",
    "    return distance\n",
    "\n",
    "min_max_scaler_01 = preprocessing.MinMaxScaler(feature_range=(0,1), copy=True)\n",
    "\n",
    "dfabcorrect=['10.49.223.194','10.49.212.206','10.49.141.206','10.56.34.134','10.49.253.35',\n",
    "             '10.49.179.13','10.56.148.80',\n",
    "             '10.32.240.119','10.49.21.125','10.56.148.238']\n",
    "dfabcorrect_set = set(dfabcorrect)\n",
    "\n",
    "\n",
    "IPnumlist = pd.concat([dfinit[\"sip\"], dfinit[\"dip\"]], axis=0)\n",
    "IPnumlist=IPnumlist.drop_duplicates()\n",
    "IPnumlist.reset_index(drop=True, inplace=True)\n",
    "IPnum= IPnumlist.shape[0]\n",
    "\n",
    "def Metric(abIP,TP,FN):\n",
    "    FP=abIP-TP\n",
    "    TN=IPnum-abIP-FN\n",
    "    R= TP/(TP+FN)\n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = FP/(TN+FP)\n",
    "    P= TP/(TP+FP)\n",
    "    return round(R, 4),round(TPR, 4),round(FPR, 4),round(P, 4)\n",
    "\n",
    "Dslist = [df_only_login,df_with_db]\n",
    "final_dslist = []\n",
    "\n",
    "#Define K1 K2 w1 w2 ,model(k-means++ or random)\n",
    "K_1=2\n",
    "K_2=1\n",
    "w_1=1\n",
    "w_2=3\n",
    "# model = \"k-means++\"\n",
    "model = \"random\"\n",
    "\n",
    "\n",
    "def AbDetect(K1,K2,w1,w2,model):\n",
    "    for ds in Dslist:\n",
    "        #########Group by < hour,sip,dip >###########\n",
    "        mmfeature=[x for x in ds.columns if x not in ['tih','sip','dip', 'No.','dbtype','hour','day','nday','numSum','sqlnumSum']]\n",
    "        kmfeature = pd.DataFrame((ds[mmfeature] != 0).any(axis=0))\n",
    "        kmfeaturelist = kmfeature[kmfeature[0]==True].index.tolist()\n",
    "        kmfeature_len = len(kmfeaturelist)\n",
    "\n",
    "        dfexp = copy.deepcopy(ds)\n",
    "        groups_hsd = dfexp.groupby(['hour','sip','dip'])\n",
    "\n",
    "        holding = {}\n",
    "        i = 0\n",
    "        for (k1,k2,k3),group in groups_hsd:\n",
    "            dfexpi = group\n",
    "            ###reset_index\n",
    "            dfexpi.reset_index(drop=True, inplace=True)\n",
    "            ######Normalization\n",
    "            for col in dfexpi[mmfeature]:\n",
    "                dfexpi[[col]]=min_max_scaler_01.fit_transform(dfexpi[[col]])\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                # Get the distance of each point to the cluster center\n",
    "                if(dfexpi.shape[0] >= K1):\n",
    "                    distance = getDistanceByPoint(dfexpi[kmfeaturelist], KMeans(n_clusters=K1,init=model).fit(dfexpi[kmfeaturelist]),dfexpi,False)\n",
    "                else:\n",
    "                    distance = getDistanceByPoint(dfexpi[kmfeaturelist], KMeans(n_clusters=1,init=model).fit(dfexpi[kmfeaturelist]),dfexpi,False)\n",
    "            dfexpi['tsp_distance'] = distance\n",
    "            holding[i] = dfexpi\n",
    "            i+=1\n",
    "        tsp_final = pd.concat(list(holding.values()), ignore_index=True)\n",
    "\n",
    "        ### Group by < sip >\n",
    "        dfexp_sip = copy.deepcopy(ds)\n",
    "        column_uniques_sip = dfexp_sip['sip'].unique() \n",
    "        groups_sip = dfexp_sip.groupby('sip')\n",
    "        kmfeature_sip=[x for x in dfexp_sip.columns if x in ['dip','numSum','sqlnumSum']]\n",
    "\n",
    "        holding_sip = {}\n",
    "        i = 0\n",
    "        for column_sip in column_uniques_sip:\n",
    "            dfexpi_sip = groups_sip.get_group(column_sip)\n",
    "            dfexpi_sip.reset_index(drop=True, inplace=True)\n",
    "            ######Normalization\n",
    "            dfexpi_sip[['dip']] = min_max_scaler_01.fit_transform(dfexpi_sip[['dip']])\n",
    "            dfexpi_sip[['numSum']] = min_max_scaler_01.fit_transform(dfexpi_sip[['numSum']])\n",
    "            dfexpi_sip[['sqlnumSum']] = min_max_scaler_01.fit_transform(dfexpi_sip[['sqlnumSum']])\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                #  Get the distance of each point to the cluster center\n",
    "                if(dfexpi_sip.shape[0] >= K2):\n",
    "                    distance_sip = getDistanceByPoint(dfexpi_sip[kmfeature_sip], KMeans(n_clusters=K2,init=model).fit(dfexpi_sip[kmfeature_sip]),dfexpi_sip,True)\n",
    "                else:\n",
    "                    distance_sip = getDistanceByPoint(dfexpi_sip[kmfeature_sip], KMeans(n_clusters=1,init=model).fit(dfexpi_sip[kmfeature_sip]),dfexpi_sip,True)\n",
    "\n",
    "            dfexpi_sip['sip_distance'] = distance_sip\n",
    "            holding_sip[i] = dfexpi_sip\n",
    "            i+=1\n",
    "        sipfinal = pd.concat(list(holding_sip.values()), ignore_index=True)\n",
    "\n",
    "\n",
    "        ### Group by < dip >\n",
    "        dfexp_dip = copy.deepcopy(ds)\n",
    "        column_uniques_dip = dfexp_dip['dip'].unique()\n",
    "        groups_dip = dfexp_dip.groupby('dip')\n",
    "        kmfeature_dip=[x for x in dfexp_dip.columns if x in ['sip','numSum','sqlnumSum']]\n",
    "        holding_dip = {}\n",
    "        i = 0\n",
    "        for column_dip in column_uniques_dip:\n",
    "            dfexpi_dip = groups_dip.get_group(column_dip)\n",
    "            dfexpi_dip.reset_index(drop=True, inplace=True)\n",
    "            ######Normalization\n",
    "            dfexpi_dip[['sip']] = min_max_scaler_01.fit_transform(dfexpi_dip[['sip']])\n",
    "            dfexpi_dip[['numSum']] = min_max_scaler_01.fit_transform(dfexpi_dip[['numSum']])\n",
    "            dfexpi_dip[['sqlnumSum']] = min_max_scaler_01.fit_transform(dfexpi_dip[['sqlnumSum']])\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                #  Get the distance of each point to the cluster center\n",
    "                if(dfexpi_dip.shape[0] >= K2):\n",
    "                    distance_dip = getDistanceByPoint(dfexpi_dip[kmfeature_dip], KMeans(n_clusters=K2,init=model).fit(dfexpi_dip[kmfeature_dip]),dfexpi_dip,True)\n",
    "                else:\n",
    "                    distance_dip = getDistanceByPoint(dfexpi_dip[kmfeature_dip], KMeans(n_clusters=1,init=model).fit(dfexpi_dip[kmfeature_dip]),dfexpi_dip,True)\n",
    "\n",
    "            dfexpi_dip['dip_distance'] = distance_dip\n",
    "            holding_dip[i] = dfexpi_dip\n",
    "            i+=1\n",
    "        dipfinal = pd.concat(list(holding_dip.values()), ignore_index=True)\n",
    "        \n",
    "        ### Integrate ds\n",
    "        #### ！Important\n",
    "        tsp_final.sort_values(by=\"No.\" , inplace=True, ascending=True)\n",
    "        sipfinal.sort_values(by=\"No.\" , inplace=True, ascending=True)\n",
    "        dipfinal.sort_values(by=\"No.\" , inplace=True, ascending=True)\n",
    "        #### ！Important reset_index\n",
    "        tsp_final.reset_index(drop=True, inplace=True)\n",
    "        sipfinal.reset_index(drop=True, inplace=True)\n",
    "        dipfinal.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        tsp_final['sip_distance'] = sipfinal['sip_distance']\n",
    "        tsp_final['dip_distance'] = dipfinal['dip_distance']\n",
    "        wadjust = (kmfeature_len**0.5/(len(kmfeature_dip)**0.5/1))\n",
    "#         wadjust = 1\n",
    "        \n",
    "        #######Calculate the final score\n",
    "        tsp_final['final_distance'] = w1*tsp_final['tsp_distance'] + wadjust*w2*tsp_final['sip_distance'] + wadjust*w2*tsp_final['dip_distance']###adjust the weights\n",
    "\n",
    "        ds.reset_index(drop=True, inplace=True)\n",
    "        ds['final_distance'] = tsp_final['final_distance']\n",
    "        final_ds = copy.deepcopy(ds)\n",
    "\n",
    "        for i in range(final_ds.shape[0]):\n",
    "            final_ds.loc[i,'sip'] = socket.inet_ntoa(struct.pack('I',socket.htonl(int(final_ds.loc[i,'sip']))))\n",
    "            final_ds.loc[i,'dip'] = socket.inet_ntoa(struct.pack('I',socket.htonl(int(final_ds.loc[i,'dip']))))\n",
    "            \n",
    "        final_ds.sort_values(by=\"No.\",inplace=True, ascending=True)\n",
    "        \n",
    "        final_dslist.append(final_ds)\n",
    "        \n",
    "    final = reduce(lambda left,right: pd.merge(left,right,how='outer'),final_dslist)\n",
    "    finalsort_ = final.sort_values([\"final_distance\"],ascending=False)\n",
    "    finalsort_.reset_index(drop=True, inplace=True)\n",
    "    return finalsort_\n",
    "\n",
    "#######Define logdf to store logs for visualization\n",
    "Logdf = pd.DataFrame(columns=('Model','K1','K2','w1','w2','ROC_AUC','PRC_AUC','TimeCost'))\n",
    "\n",
    "time_start = time.time()\n",
    "#########Detection########\n",
    "finalsort = AbDetect(K_1,K_2,w_1,w_2,model)\n",
    "time_end = time.time()\n",
    "cost = round((time_end - time_start),4)\n",
    "\n",
    "#######Define Lists to keep TPR FPR R P\n",
    "TPRlist = []\n",
    "FPRlist = []\n",
    "Plist = []\n",
    "Rlist = []\n",
    "\n",
    "num=1\n",
    "while num < finalsort.shape[0]+1:\n",
    "    ab_finalsort= finalsort[0:num]\n",
    "    num += 1\n",
    "    dfabip=pd.concat([ab_finalsort[\"sip\"], ab_finalsort[\"dip\"]], axis=0)\n",
    "    dfabip=dfabip.drop_duplicates()\n",
    "    dfabip.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    dfabip.tolist()\n",
    "    dfabip_set = set(dfabip)\n",
    "    bingo=(dfabip_set)&(dfabcorrect_set)\n",
    "    abIPi=len(dfabip)\n",
    "    TPi=len(bingo)\n",
    "    FNi=len(dfabcorrect)-TPi\n",
    "\n",
    "    R,TPR,FPR,P = Metric(abIPi,TPi,FNi)\n",
    "    TPRlist.append(TPR)\n",
    "    FPRlist.append(FPR)\n",
    "    Plist.append(P)\n",
    "    Rlist.append(R)\n",
    "\n",
    "ROC = pd.DataFrame(FPRlist, columns=['FPR'])\n",
    "ROC = pd.concat([ROC, pd.DataFrame(TPRlist,columns=['TPR'])],axis=1)\n",
    "PR = pd.DataFrame(Rlist, columns=['R'])\n",
    "PR = pd.concat([PR, pd.DataFrame(Plist,columns=['P'])],axis=1)\n",
    "\n",
    "####Importance drop_duplicates\n",
    "ROC=ROC.drop_duplicates()\n",
    "PR=PR.drop_duplicates()\n",
    "\n",
    "####Importance sort_values\n",
    "ROC.sort_values(by=['FPR','TPR'],inplace=True,ascending=True)\n",
    "PR.sort_values(by=['R','P'],inplace=True,ascending=[True,False])\n",
    "ROC.reset_index(drop=True, inplace=True)\n",
    "PR.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "#####Importance Add the last line For ROC\n",
    "ROC.loc[ROC.shape[0]] = [1,ROC.loc[ROC.shape[0]-1,'TPR']]\n",
    "#####Importance Add the first line For PR\n",
    "PR.loc[-1] = [0,PR.loc[0,'P']]\n",
    "PR.index = PR.index + 1\n",
    "PR.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "#####AUC\n",
    "ROC_AUC = np.trapz(list(ROC['TPR']),list(ROC['FPR'])).round(4)\n",
    "PRC_AUC = np.trapz(list(PR['P']),list(PR['R'])).round(4)\n",
    "\n",
    "######Save Logs\n",
    "# Path_ROC = \"Results/Batch_Testing/ROC_Model%s_K%d%d_w%d%d.csv\"%(model,i,j,m,n)\n",
    "# ROC.to_csv(Path_ROC,index=0)\n",
    "# Path_PRC = \"Results/Batch_Testing/PRC_Model%s_K%d%d_w%d%d.csv\"%(model,K_1,K_2,w_1,w_2)\n",
    "# PR.to_csv(Path_PRC,index=0)\n",
    "\n",
    "Logdf = Logdf.append({'Model':model,'K1':K_1,'K2':K_2,'w1':w_1,'w2':w_2,'ROC_AUC':ROC_AUC,'PRC_AUC':PRC_AUC,'TimeCost':cost}, ignore_index=True)\n",
    "# Logdf.to_csv(\"Results/Batch_Testing/All_Logs.csv\",index=0)\n",
    "print(Logdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logdf.to_csv(\"Results/Batch_Testing/All_Logs.csv\",index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction for DFADR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>P</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R       P  num\n",
       "0  1.0  0.8333   46"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalsort = AbDetect(2,1,1,3,model)\n",
    "\n",
    "##########Take R=1 and P is the highest\n",
    "TPRlist = []\n",
    "FPRlist = []\n",
    "Plist = []\n",
    "Rlist = []\n",
    "numlist = []\n",
    "\n",
    "num = 1\n",
    "while num < finalsort.shape[0]+1:\n",
    "\n",
    "\n",
    "    ab_finalsort= finalsort[0:num]\n",
    "    num += 1\n",
    "    \n",
    "    dfabip=pd.concat([ab_finalsort[\"sip\"], ab_finalsort[\"dip\"]], axis=0)\n",
    "    dfabip=dfabip.drop_duplicates()\n",
    "    dfabip.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # print(dfabip)\n",
    "\n",
    "    dfabip.tolist()\n",
    "    dfabip_set = set(dfabip)\n",
    "    \n",
    "    bingo=(dfabip_set)&(dfabcorrect_set)\n",
    "\n",
    "    abIPi=len(dfabip)\n",
    "    TPi=len(bingo)\n",
    "    FNi=len(dfabcorrect)-TPi\n",
    "    \n",
    "    R,TPR,FPR,P = Metric(abIPi,TPi,FNi)\n",
    "    \n",
    "    #####Only Keep R==1\n",
    "    if R == 1:\n",
    "        numlist.append(num-1)\n",
    "        Plist.append(P)\n",
    "        Rlist.append(R)\n",
    "    \n",
    "PRKeep = pd.DataFrame(Rlist, columns=['R'])\n",
    "PRKeep = pd.concat([PRKeep, pd.DataFrame(Plist,columns=['P'])],axis=1)\n",
    "PRKeep = pd.concat([PRKeep, pd.DataFrame(numlist,columns=['num'])],axis=1)\n",
    "\n",
    "\n",
    "PRKeep.sort_values(by=['R','P'],inplace=True,ascending=True)\n",
    "PRKeep.drop_duplicates(subset=['R'],keep='last', inplace=True)\n",
    "PRKeep.reset_index(drop=True, inplace=True)\n",
    "PRKeep\n",
    "\n",
    "# ####Importance drop_duplicates\n",
    "# ROC=ROC.drop_duplicates()\n",
    "# PR=PR.drop_duplicates()\n",
    "\n",
    "# ####Importance sort_values\n",
    "# ROC.sort_values(by=['FPR','TPR'],inplace=True,ascending=True)\n",
    "# PR.sort_values(by=['R','P'],inplace=True,ascending=True)\n",
    "        \n",
    "# ROC.reset_index(drop=True, inplace=True)\n",
    "# PR.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRKeep['num'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tih</th>\n",
       "      <th>sip</th>\n",
       "      <th>dip</th>\n",
       "      <th>num</th>\n",
       "      <th>difsport</th>\n",
       "      <th>difpw</th>\n",
       "      <th>difinfo</th>\n",
       "      <th>difuser</th>\n",
       "      <th>sqlnum</th>\n",
       "      <th>difsqlinfo</th>\n",
       "      <th>dbtype</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>numSum</th>\n",
       "      <th>sqlnumSum</th>\n",
       "      <th>nday</th>\n",
       "      <th>No.</th>\n",
       "      <th>final_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-11 19:00:00</td>\n",
       "      <td>10.49.141.206</td>\n",
       "      <td>10.49.253.35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>220</td>\n",
       "      <td>7.127453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-11 21:00:00</td>\n",
       "      <td>10.49.223.194</td>\n",
       "      <td>10.49.253.35</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>db</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>897</td>\n",
       "      <td>6.778072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-11 19:00:00</td>\n",
       "      <td>10.49.141.206</td>\n",
       "      <td>10.49.253.35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>220</td>\n",
       "      <td>6.506444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-11 21:00:00</td>\n",
       "      <td>10.49.223.194</td>\n",
       "      <td>10.49.253.35</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>db</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>897</td>\n",
       "      <td>6.340306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-06 19:00:00</td>\n",
       "      <td>10.56.34.134</td>\n",
       "      <td>10.49.253.35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>db</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1279</td>\n",
       "      <td>4.153079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tih            sip           dip  num  difsport  difpw  \\\n",
       "0 2019-06-11 19:00:00  10.49.141.206  10.49.253.35    1         1      1   \n",
       "1 2019-06-11 21:00:00  10.49.223.194  10.49.253.35   13        13     13   \n",
       "2 2019-06-11 19:00:00  10.49.141.206  10.49.253.35    1         1      1   \n",
       "3 2019-06-11 21:00:00  10.49.223.194  10.49.253.35   13        13     13   \n",
       "4 2019-06-06 19:00:00   10.56.34.134  10.49.253.35    1         1      1   \n",
       "\n",
       "   difinfo  difuser  sqlnum  difsqlinfo dbtype  day  hour  numSum  sqlnumSum  \\\n",
       "0        1        1       0           0      0   11    19       1          0   \n",
       "1        1        1      17           3     db   11    21      13         17   \n",
       "2        1        1       0           0      0   11    19       1          0   \n",
       "3        1        1      17           3     db   11    21      13         17   \n",
       "4        1        1       4           4     db    6    19       8         32   \n",
       "\n",
       "   nday   No.  final_distance  \n",
       "0     1   220        7.127453  \n",
       "1     1   897        6.778072  \n",
       "2     1   220        6.506444  \n",
       "3     1   897        6.340306  \n",
       "4     2  1279        4.153079  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_final_output= finalsort[0:PRKeep['num'][0]]\n",
    "ab_final_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_final_output.to_csv(\"Results/WebBackend_for_DFADR.csv\",index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "310px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
